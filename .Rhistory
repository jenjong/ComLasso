1:10, ylab="coeffients",cex.axis=0.8, cex.lab=0.7,
xlab=expression(sum(hat(beta)[j](lambda),j=1,107)/sum(abs(hat(beta)[j](0)),j==1,107)), lwd=3, breaks=FALSE)
fit2$beta.rec[[1]])
fit2$beta.rec[[1]]
matplot(a/b,t(fit2$beta.rec[[1]]),type="l",ylim=c(-0.5,0.5),ylab="coeffients",cex.axis=0.8, cex.lab=0.9,
xlab=expression(sum(hat(beta)[j](lambda),j=1,107)/sum(abs(hat(beta)[j](0)),j==1,107)), lwd=3, main=uphylum[1])
gs[,1]
load("bsi_new_result_20190209.RData")
library(comlasso)
lab.fx <- vector(mode="list", 4)
lab.fx2 <- vector(mode="list", 4)
gname <- colnames(x)
lvs <- rep(0, length(gname))
for(j in 1:4){
sfx <- sort(gs[,j], decreasing=T, index.return=T)
sgs <- gs[sfx$ix,j]
sgname <- gname[sfx$ix]
num <- match(sgname,gname)
pos <- 1:10
lab.fx[[j]] <- rep(0, length(pos))
for(i in 1:length(pos)){
lab.fx[[j]][i] <- paste(i, ". ",sgname[pos[i]]," (",round(sgs[pos[i]],3),")",sep="")
if(num[i]>=1 & num[i] <=20){
lvs[i] <- 1
}else if(num[i]>=21 & num[i] <=30){
lvs[i] <- 2
}else if(num[i]>=31 & num[i] <=92){
lvs[i] <- 3
}else if(num[i]>=93 & num[i] <=107){
lvs[i] <- 4
}
lab.fx2[[j]][i] <- paste(uphylum[lvs[i]], ". ",sgname[pos[i]]," (",round(sgs[pos[i]],3),")",sep="")
}
}
# 1. classification with marginal association
wt <- function(x,y){wilcox.test(x[y==1], x[y==-1])$p.value}
pval <- apply(x[,gname],2,wt,y)
sfx <- sort(pval, decreasing=F, index.return=T)
sgs <- pval[sfx$ix]
sgname <- gname[sfx$ix]
num <- match(sgname, gname)
pos <- 1:10
lab.fx.ma <- rep(0, length(pos))
lab.fx.ma2 <- rep(0, length(pos))
for(i in 1:length(pos)){
lab.fx.ma[i] <- paste(i, ". ",sgname[pos[i]]," (",round(sgs[pos[i]],3),")",sep="")
if(num[i]>=1 & num[i] <=20){
lvs[i] <- 1
}else if(num[i]>=21 & num[i] <=30){
lvs[i] <- 2
}else if(num[i]>=31 & num[i] <=92){
lvs[i] <- 3
}else if(num[i]>=93 & num[i] <=107){
lvs[i] <- 4
}
lab.fx.ma2[i] <- paste(uphylum[lvs[i]], ". ",sgname[pos[i]]," (",round(sgs[pos[i]],3),")",sep="")
}
### Table 3
library(xtable); xtable(cbind(lab.fx2[[2]][1:10],lab.fx2[[4]][1:10],lab.fx.ma2[1:10]))
library(xtable); xtable(cbind(lab.fx[[2]][1:13],lab.fx[[4]][1:13],lab.fx.ma[1:13]))
# tmp <- data.frame(ugenera,pval)
# aa <- tmp[sort(tmp[,2],decreasing=F,index=T)$ix,][1:10,]
# names(ugenera) <- ugenera
# selvar <- match(as.character(aa[,1]), ugenera)
# xtable(aa,digits=3)
#######################################################################
##1. gamma=0 & top-ranked 10 genes selected by marginal association   #
#######################################################################
fit1 <- comlasso(ltype="classification", n, p=1, K=length(selvar), x[,selvar], y, gam=0, weights=NULL)
#matplot(t(fit$beta.rec[[1]]),type="b",lty=2)
can.lam <- exp(seq(log(max(fit1$lambda)),1e-5,length=50))
can.gam <- c(-0.2,-0.1,0)
mgs1 <- vector(mode="list",length=length(can.gam))
for(j in 1:length(can.gam))
mgs1[[j]] <- matrix(0,28,length(can.lam))
for(j in 1:length(can.gam)){
for(i in 1:28){
loo <- comlasso(ltype="classification", n-1, p=1, K=length(selvar), x[-i,selvar], y[-i], gam=can.gam[j], weights=NULL)
est <- predict.comlasso(loo,newx=x[i,selvar,drop=F],s=can.lam,type="fit",mode="lambda")$fit
mgs1[[j]][i,] <- est*y[i]
}
}
# Figure 2 (c)
par(mar=c(5,4,4,3)-c(0.8,-0.2,3,1.8))
plot(can.lam,apply(mgs1[[1]],2,function(x){mean(x<0)}),
col=1,lty=1,type="s",lwd=2,
ylab="leave-one-out error rate",
xlab=expression(lambda),ylim=c(0.10,0.55),
cex=1.5,cex.axis=1.2,cex.lab=1.5)
points(apply(mgs1[[2]],2,function(x){mean(x<0)}),col=2,lty=2,type="s",lwd=2,cex=2)
points(apply(mgs1[[3]],2,function(x){mean(x<0)}),col=3,lty=3,type="s",lwd=2,cex=2)
legend(3,0.2,legend=c(expression(gamma==-0.2),expression(gamma==-0.1),expression(gamma==0)),col=c(1,2,3),lty=c(1,2,3),bty="n",ncol=1,cex=1.5)
####################################
# 2. classification with complasso #
####################################
# comlassoA
# fit2 with 107
fit2 <- comlasso(ltype="classification",n,p=1,K=107,max.steps=100,
x,y,gam=0,weights=NULL)
par(mar=c(5.1, 4.1, 4.1, 2.1)-c(0,0,2,-1.5))
matplot.comlasso1(fit2$lambda,t(fit2$beta.rec[[1]][sort(gs[,1],decreasing=T,index=T)$ix,]),
1:10, ylab="coeffients",cex.axis=0.8, cex.lab=0.7,
xlab=expression(sum(hat(beta)[j](lambda),j=1,107)/sum(abs(hat(beta)[j](0)),j==1,107)), lwd=3, breaks=FALSE)
###
can.lam <- exp(seq(log(max(fit2$lambda)),1e-5,length=50))
can.gam <- c(-0.2,-0.1,0)
mgs2 <- vector(mode="list",length=length(can.gam))
for(j in 1:length(can.gam))
mgs2[[j]] <- matrix(0,28,length(can.lam))
for(j in 1:length(can.gam)){
for(i in 1:28){
loo <- comlasso(ltype="classification",n-1,p=1,K=107,max.steps=1e2,x[-i,],y[-i],gam=can.gam[j], weights=NULL)
est <- predict.comlasso(loo,newx=x[i,,drop=F],s=can.lam,type="fit",mode="lambda")$fit
mgs2[[j]][i,] <- est*y[i]
}
}
## Figure3 (a)
par(mar=c(5,4,4,3)-c(0.8,-0.2,3,1.8))
plot(can.lam,apply(mgs2[[1]],2,function(x){mean(x<0)}),
col=1,lty=1,type="s",lwd=2,
ylab="leave-one-out error rate",
xlab=expression(lambda),ylim=c(0.10,0.55),
cex=1.5,cex.axis=1.2,cex.lab=1.5)
points(can.lam, apply(mgs2[[2]],2,function(x){mean(x<0)}),col=2,lty=2,type="s",lwd=2,cex=2)
points(can.lam, apply(mgs2[[3]],2,function(x){mean(x<0)}),col=3,lty=3,type="s",lwd=2,cex=2)
legend(3,0.2,legend=c(expression(gamma==-0.2),expression(gamma==-0.1),expression(gamma==0)),col=c(1,2,3),lty=c(1,2,3),bty="n",ncol=1,cex=1.5)
#######################################################
### comlassoB
### fit3 with K=4
#######################################################
load("bsi_new_result_20190209.RData")
library(comlasso)
fit3 <- comlasso(ltype="classification",n,p=length(K),K=K,
max.steps=100,x2,y,gam=0,weights=NULL)
# solution path
coeffs <- predict.comlasso(fit3,newx=x2,s=fit3$lambda,type="coefficients",mode="lambda")$coefficients
b <- sum(abs(coeffs[71,]))
a <- rowSums(abs(coeffs))
par(mfrow=c(2,2),mar=c(5.1, 4.1, 4.1, 2.1)-c(0,2,2,1.5))
matplot(a/b,t(fit3$beta.rec[[1]]),type="l",ylim=c(-0.5,0.5),ylab="coeffients",cex.axis=0.8, cex.lab=0.9,
xlab=expression(sum(hat(beta)[j](lambda),j=1,107)/sum(abs(hat(beta)[j](0)),j==1,107)), lwd=3, main=uphylum[1])
matplot(a/b,t(fit3$beta.rec[[2]]),type="l",ylim=c(-0.5,0.5),ylab="coeffients",cex.axis=0.8, cex.lab=0.9,
xlab=expression(sum(hat(beta)[j](lambda),j=1,107)/sum(abs(hat(beta)[j](0)),j==1,107)), lwd=3, main=uphylum[2])
matplot(a/b,t(fit3$beta.rec[[3]]),type="l",ylim=c(-0.5,0.5),ylab="coeffients",cex.axis=0.8, cex.lab=0.9,
xlab=expression(sum(hat(beta)[j](lambda),j=1,107)/sum(abs(hat(beta)[j](0)),j==1,107)), lwd=3, main=uphylum[3])
matplot(a/b,t(fit3$beta.rec[[4]]),type="l",ylim=c(-0.5,0.5),ylab="coeffients",cex.axis=0.8, cex.lab=0.9,
xlab=expression(sum(hat(beta)[j](lambda),j=1,107)/sum(abs(hat(beta)[j](0)),j==1,107)), lwd=3, main=uphylum[4])
can.lam <- exp(seq(log(max(fit3$lambda)),1e-5,length=50))
can.gam <- c(-0.2,-0.1,0)
mgs3 <- vector(mode="list",length=length(can.gam))
for(j in 1:length(can.gam))
mgs3[[j]] <- matrix(0,28,length(can.lam))
for(j in 1:length(can.gam)){
for(i in 1:28){
loo <- comlasso(ltype="classification",n-1,p=length(K),K=K,
max.steps=1e2,x2[-i,],y[-i],gam=can.gam[j], weights=NULL)
print(i)
est <- predict.comlasso(loo,newx=x2[i,,drop=F],s=can.lam,type="fit",mode="lambda")$fit
mgs3[[j]][i,] <- est*y[i]
}
}
par(mar=c(5,4,4,3)-c(0.8,-0.2,3,1.8))
plot(can.lam, apply(mgs3[[1]],2,function(x){mean(x<0)}),
col=1,lty=1,type="s",lwd=2,
ylab="leave-one-out error rate",
xlab=expression(lambda),ylim=c(0.10,0.55),
cex=1.5,cex.axis=1.2,cex.lab=1.5)
points(apply(mgs3[[2]],2,function(x){mean(x<0)}),col=2,lty=2,type="s",lwd=2,cex=2)
points(apply(mgs3[[3]],2,function(x){mean(x<0)}),col=3,lty=3,type="s",lwd=2,cex=2)
legend(3,0.2,legend=c(expression(gamma==-0.2),expression(gamma==-0.1),expression(gamma==0)),col=c(1,2,3),lty=c(1,2,3),bty="n",ncol=1,cex=1.5)
#
#save.image(file="bsi_result_full.RData")
selvar
ugenera
comlasso
###### Figure 3 (left panel) ######
fit2 <- comlasso(ltype="classification",n,p=107,K=1,max.steps=100,
x,y,gam=0,weights=NULL)
###### Figure 3 (left panel) ######
fit2 <- comlasso(ltype="classification",n,p=1,K=107,max.steps=100,
x,y,gam=0,weights=NULL)
fit2
names(fit2)
fit2$beta.rec
fit2$beta.rec[[1]]
dim(fit2$beta.rec[[1]])
length(K)
K
comlasso
K
rm(list = ls())
# load data
load("./bsi_new.RData");
K
fit2$beta.rec
###### Figure 3 (left panel) ######
fit2 <- comlasso(ltype="classification",n,p=1,K=107,max.steps=100,
x,y,gam=0,weights=NULL)
rm(list = ls())
# load data
load("./bsi_new.RData");
library(comlasso)
n <- 28
gs <- matrix(0,107,4)
gname <- colnames(x)
wt <- function(x,y){wilcox.test(x[y==1], x[y==-1])$p.value}
pval <- apply(x[,gname],2,wt,y)
tmp <- data.frame(ugenera,pval)
aa <- tmp[sort(tmp[,2],decreasing=F,index=T)$ix,][1:10,]
names(ugenera) <- ugenera
selvar <- match(as.character(aa[,1]), ugenera)
###### Figure 3 (left panel) ######
fit2 <- comlasso(ltype="classification",n,p=1,K=107,max.steps=100,
x,y,gam=0,weights=NULL)
fit2$beta.rec
fit2$beta.rec[[1]]
fit2$beta.rec[[1]]
dim(fit2$beta.rec[[1]])
fit2$lambda
length(fit2$lambda)
dim(fit2$beta.rec[[1]])
t(fit2$beta.rec[[1]][1:20,])
matplot.comlasso1(fit2$lambda,t(fit2$beta.rec[[1]][1:20,]),
1:10, ylab="coeffients",cex.axis=0.8, cex.lab=0.7,
xlab=expression(sum(hat(beta)[j](lambda),j=1,107)/sum(abs(hat(beta)[j](0)),j==1,107)), lwd=3, breaks=FALSE)
matplot(a/b,t(fit2$beta.rec[[1]][1:20,]),type="l",ylim=c(-0.5,0.5),ylab="coeffients",cex.axis=0.8, cex.lab=0.9,
xlab=expression(sum(hat(beta)[j](lambda),j=1,107)/sum(abs(hat(beta)[j](0)),j==1,107)), lwd=3, main=uphylum[1])
coeffs <- predict.comlasso(fit2,newx=x2,s=fit2$lambda,type="coefficients",mode="lambda")$coefficients
b <- sum(abs(coeffs[71,]))
a <- rowSums(abs(coeffs))
coeffs <- predict.comlasso(fit2,newx=x2,s=fit2$lambda,type="coefficients",mode="lambda")$coefficients
coeffs
dim(coeffs)
b <- sum(abs(coeffs[56,]))
a <- rowSums(abs(coeffs))
matplot(a/b,t(fit2$beta.rec[[1]][1:20,]),type="l",ylim=c(-0.5,0.5),ylab="coeffients",cex.axis=0.8, cex.lab=0.9,
xlab=expression(sum(hat(beta)[j](lambda),j=1,107)/sum(abs(hat(beta)[j](0)),j==1,107)), lwd=3, main=uphylum[1])
coeffs
dim(coeffs_
dim(coeffs)
nrow(coeffs)
b <- sum(abs(coeffs[nrow(coeffs),]))
b
a <- rowSums(abs(coeffs))
a
b
par(mar=c(5.1, 4.1, 4.1, 2.1)-c(0,0,2,-1.5))
matplot(a/b,t(fit2$beta.rec[[1]][1:20,]),type="l",ylim=c(-0.5,0.5),ylab="coeffients",cex.axis=0.8, cex.lab=0.9,
xlab=expression(sum(hat(beta)[j](lambda),j=1,107)/sum(abs(hat(beta)[j](0)),j==1,107)), lwd=3, main=uphylum[1])
K
matplot(a/b,t(fit2$beta.rec[[1]][21:30,]),type="l",ylim=c(-0.5,0.5),ylab="coeffients",cex.axis=0.8, cex.lab=0.9,
xlab=expression(sum(hat(beta)[j](lambda),j=1,107)/sum(abs(hat(beta)[j](0)),j==1,107)), lwd=3, main=uphylum[2])
matplot(a/b,t(fit2$beta.rec[[1]][31:92,]),type="l",ylim=c(-0.5,0.5),ylab="coeffients",cex.axis=0.8, cex.lab=0.9,
xlab=expression(sum(hat(beta)[j](lambda),j=1,107)/sum(abs(hat(beta)[j](0)),j==1,107)), lwd=3, main=uphylum[3])
#par(mar=c(5.1, 4.1, 4.1, 2.1)-c(0,0,2,-1.5))
matplot(a/b,t(fit2$beta.rec[[1]][1:20,]),type="l",ylim=c(-0.5,0.5),ylab="coeffients",cex.axis=0.8, cex.lab=0.9,
xlab=expression(sum(hat(beta)[j](lambda),j=1,107)/sum(abs(hat(beta)[j](0)),j==1,107)), lwd=3, main=uphylum[1])
matplot(a/b,t(fit2$beta.rec[[1]][21:30,]),type="l",ylim=c(-0.5,0.5),ylab="coeffients",cex.axis=0.8, cex.lab=0.9,
xlab=expression(sum(hat(beta)[j](lambda),j=1,107)/sum(abs(hat(beta)[j](0)),j==1,107)), lwd=3, main=uphylum[2])
matplot(a/b,t(fit2$beta.rec[[1]][31:92,]),type="l",ylim=c(-0.5,0.5),ylab="coeffients",cex.axis=0.8, cex.lab=0.9,
xlab=expression(sum(hat(beta)[j](lambda),j=1,107)/sum(abs(hat(beta)[j](0)),j==1,107)), lwd=3, main=uphylum[3])
matplot(a/b,t(fit2$beta.rec[[1]][31:92,]),type="l",ylim=c(-0.5,0.5),ylab="coeffients",cex.axis=0.8, cex.lab=0.9,
xlab=expression(sum(hat(beta)[j](lambda),j=1,107)/sum(abs(hat(beta)[j](0)),j==1,107)), lwd=3, main=uphylum[3])
matplot(a/b,t(fit2$beta.rec[[1]][93:107,]),type="l",ylim=c(-0.5,0.5),ylab="coeffients",cex.axis=0.8, cex.lab=0.9,
xlab=expression(sum(hat(beta)[j](lambda),j=1,107)/sum(abs(hat(beta)[j](0)),j==1,107)), lwd=3, main=uphylum[4])
fit2 <- comlasso(ltype="classification",n,p=1,K=107,max.steps=100,
x,y,gam=0,weights=NULL)
coeffs <- predict.comlasso(fit2,newx=x2,s=fit2$lambda,type="coefficients",mode="lambda")$coefficients
b <- sum(abs(coeffs[nrow(coeffs),]))
a <- rowSums(abs(coeffs))
matplot(a/b,t(fit2$beta.rec[[1]][1:20,]),type="l",ylim=c(-0.5,0.5),ylab="coeffients",cex.axis=0.8, cex.lab=0.9,
xlab=expression(sum(hat(beta)[j](lambda),j=1,107)/sum(abs(hat(beta)[j](0)),j==1,107)), lwd=3, main=uphylum[1])
matplot(a/b,t(fit2$beta.rec[[1]][21:30,]),type="l",ylim=c(-0.5,0.5),ylab="coeffients",cex.axis=0.8, cex.lab=0.9,
xlab=expression(sum(hat(beta)[j](lambda),j=1,107)/sum(abs(hat(beta)[j](0)),j==1,107)), lwd=3, main=uphylum[2])
matplot(a/b,t(fit2$beta.rec[[1]][31:92,]),type="l",ylim=c(-0.5,0.5),ylab="coeffients",cex.axis=0.8, cex.lab=0.9,
xlab=expression(sum(hat(beta)[j](lambda),j=1,107)/sum(abs(hat(beta)[j](0)),j==1,107)), lwd=3, main=uphylum[3])
matplot(a/b,t(fit2$beta.rec[[1]][93:107,]),type="l",ylim=c(-0.5,0.5),ylab="coeffients",cex.axis=0.8, cex.lab=0.9,
xlab=expression(sum(hat(beta)[j](lambda),j=1,107)/sum(abs(hat(beta)[j](0)),j==1,107)), lwd=3, main=uphylum[4])
fit3 <- comlasso(ltype="classification",n,p=length(K),K=K,
max.steps=100,x2,y,gam=0,weights=NULL)
# solution path
coeffs <- predict.comlasso(fit3,newx=x2,s=fit3$lambda,type="coefficients",mode="lambda")$coefficients
b <- sum(abs(coeffs[71,]))
a <- rowSums(abs(coeffs))
par(mfrow=c(2,2),mar=c(5.1, 4.1, 4.1, 2.1)-c(0,2,2,1.5))
matplot(a/b,t(fit3$beta.rec[[1]]),type="l",ylim=c(-0.5,0.5),ylab="coeffients",cex.axis=0.8, cex.lab=0.9,
xlab=expression(sum(hat(beta)[j](lambda),j=1,107)/sum(abs(hat(beta)[j](0)),j==1,107)), lwd=3, main=uphylum[1])
matplot(a/b,t(fit3$beta.rec[[2]]),type="l",ylim=c(-0.5,0.5),ylab="coeffients",cex.axis=0.8, cex.lab=0.9,
xlab=expression(sum(hat(beta)[j](lambda),j=1,107)/sum(abs(hat(beta)[j](0)),j==1,107)), lwd=3, main=uphylum[2])
matplot(a/b,t(fit3$beta.rec[[3]]),type="l",ylim=c(-0.5,0.5),ylab="coeffients",cex.axis=0.8, cex.lab=0.9,
xlab=expression(sum(hat(beta)[j](lambda),j=1,107)/sum(abs(hat(beta)[j](0)),j==1,107)), lwd=3, main=uphylum[3])
matplot(a/b,t(fit3$beta.rec[[4]]),type="l",ylim=c(-0.5,0.5),ylab="coeffients",cex.axis=0.8, cex.lab=0.9,
xlab=expression(sum(hat(beta)[j](lambda),j=1,107)/sum(abs(hat(beta)[j](0)),j==1,107)), lwd=3, main=uphylum[4])
fit3 <- comlasso(ltype="classification",n,p=length(K),K=K,
max.steps=100,x2,y,gam=0,weights=NULL)
# solution path
coeffs <- predict.comlasso(fit3,newx=x2,s=fit3$lambda,type="coefficients",mode="lambda")$coefficients
b <- sum(abs(coeffs[71,]))
a <- rowSums(abs(coeffs))
matplot(a/b,t(fit3$beta.rec[[1]]),type="l",ylim=c(-0.5,0.5),ylab="coeffients",cex.axis=0.8, cex.lab=0.9,
xlab=expression(sum(hat(beta)[j](lambda),j=1,107)/sum(abs(hat(beta)[j](0)),j==1,107)), lwd=3, main=uphylum[1])
matplot(a/b,t(fit3$beta.rec[[2]]),type="l",ylim=c(-0.5,0.5),ylab="coeffients",cex.axis=0.8, cex.lab=0.9,
xlab=expression(sum(hat(beta)[j](lambda),j=1,107)/sum(abs(hat(beta)[j](0)),j==1,107)), lwd=3, main=uphylum[2])
matplot(a/b,t(fit3$beta.rec[[3]]),type="l",ylim=c(-0.5,0.5),ylab="coeffients",cex.axis=0.8, cex.lab=0.9,
xlab=expression(sum(hat(beta)[j](lambda),j=1,107)/sum(abs(hat(beta)[j](0)),j==1,107)), lwd=3, main=uphylum[3])
matplot(a/b,t(fit3$beta.rec[[4]]),type="l",ylim=c(-0.5,0.5),ylab="coeffients",cex.axis=0.8, cex.lab=0.9,
xlab=expression(sum(hat(beta)[j](lambda),j=1,107)/sum(abs(hat(beta)[j](0)),j==1,107)), lwd=3, main=uphylum[4])
rm(list = ls())
# load data
load("./bsi_new.RData");
library(comlasso)
n <- 28
gs <- matrix(0,107,4)
gname <- colnames(x)
wt <- function(x,y){wilcox.test(x[y==1], x[y==-1])$p.value}
pval <- apply(x[,gname],2,wt,y)
tmp <- data.frame(ugenera,pval)
aa <- tmp[sort(tmp[,2],decreasing=F,index=T)$ix,][1:10,]
names(ugenera) <- ugenera
selvar <- match(as.character(aa[,1]), ugenera)
###### Figure 3 (left panel) ######
fit2 <- comlasso(ltype="classification",n,p=1,K=107,max.steps=100,
x,y,gam=0,weights=NULL)
coeffs <- predict.comlasso(fit2,newx=x2,s=fit2$lambda,type="coefficients",mode="lambda")$coefficients
b <- sum(abs(coeffs[nrow(coeffs),]))
a <- rowSums(abs(coeffs))
matplot(a/b,t(fit2$beta.rec[[1]][1:20,]),type="l",ylim=c(-0.5,0.5),ylab="coeffients",cex.axis=0.8, cex.lab=0.9,
xlab=expression(sum(hat(beta)[j](lambda),j=1,107)/sum(abs(hat(beta)[j](0)),j==1,107)), lwd=3, main=uphylum[1])
matplot(a/b,t(fit2$beta.rec[[1]][21:30,]),type="l",ylim=c(-0.5,0.5),ylab="coeffients",cex.axis=0.8, cex.lab=0.9,
xlab=expression(sum(hat(beta)[j](lambda),j=1,107)/sum(abs(hat(beta)[j](0)),j==1,107)), lwd=3, main=uphylum[2])
matplot(a/b,t(fit2$beta.rec[[1]][31:92,]),type="l",ylim=c(-0.5,0.5),ylab="coeffients",cex.axis=0.8, cex.lab=0.9,
xlab=expression(sum(hat(beta)[j](lambda),j=1,107)/sum(abs(hat(beta)[j](0)),j==1,107)), lwd=3, main=uphylum[3])
matplot(a/b,t(fit2$beta.rec[[1]][93:107,]),type="l",ylim=c(-0.5,0.5),ylab="coeffients",cex.axis=0.8, cex.lab=0.9,
xlab=expression(sum(hat(beta)[j](lambda),j=1,107)/sum(abs(hat(beta)[j](0)),j==1,107)), lwd=3, main=uphylum[4])
###### Figure 3 (right panel) ######
fit3 <- comlasso(ltype="classification",n,p=length(K),K=K,
max.steps=100,x2,y,gam=0,weights=NULL)
# solution path
coeffs <- predict.comlasso(fit3,newx=x2,s=fit3$lambda,type="coefficients",mode="lambda")$coefficients
b <- sum(abs(coeffs[71,]))
a <- rowSums(abs(coeffs))
matplot(a/b,t(fit3$beta.rec[[1]]),type="l",ylim=c(-0.5,0.5),ylab="coeffients",cex.axis=0.8, cex.lab=0.9,
xlab=expression(sum(hat(beta)[j](lambda),j=1,107)/sum(abs(hat(beta)[j](0)),j==1,107)), lwd=3, main=uphylum[1])
matplot(a/b,t(fit3$beta.rec[[2]]),type="l",ylim=c(-0.5,0.5),ylab="coeffients",cex.axis=0.8, cex.lab=0.9,
xlab=expression(sum(hat(beta)[j](lambda),j=1,107)/sum(abs(hat(beta)[j](0)),j==1,107)), lwd=3, main=uphylum[2])
matplot(a/b,t(fit3$beta.rec[[3]]),type="l",ylim=c(-0.5,0.5),ylab="coeffients",cex.axis=0.8, cex.lab=0.9,
xlab=expression(sum(hat(beta)[j](lambda),j=1,107)/sum(abs(hat(beta)[j](0)),j==1,107)), lwd=3, main=uphylum[3])
matplot(a/b,t(fit3$beta.rec[[4]]),type="l",ylim=c(-0.5,0.5),ylab="coeffients",cex.axis=0.8, cex.lab=0.9,
xlab=expression(sum(hat(beta)[j](lambda),j=1,107)/sum(abs(hat(beta)[j](0)),j==1,107)), lwd=3, main=uphylum[4])
rm(list = ls())
library(comlasso)
data(sand)
mdat <- sand[,-1]
x <- as.matrix(mdat[,1:3])/100
x <- log(x); y <- log(mdat[,4])
ols <- lm((x[,1]-x[,3])~y)
ols <- lm((x[,1]-x[,2])~y)
n <- nrow(x); p <- ncol(x)
ltype="regression"
set.seed(1)
f1 <- comlasso("regression", n=n, p=1, K=p, X.raw=x, y=y, gam=1e5, weights=c(1,1,1))
w <- 1/(abs(f1$beta[[1]])/sum(abs(f1$beta[[1]])))
f2 <- comlasso("regression", n=n, p=1, K=p, X.raw=x, y=y, gam=1e5, weights=w)
op <- par(mfrow=c(1,2),mai=c(1.02,0.82-0.3,0.82,0.42),mar=c(5.1,4.1+0.7,4.1,2.1))
s = rowSums(abs(t(f1$beta.rec[[1]])))
matplot(s/s[3], t(f1$beta.rec[[1]]),type="b",xaxt="n",
xlab=expression(paste(group("|", beta(lambda), "|")[1], "/" ,
group("|", beta(0), "|")[1])),
ylab=expression(hat(beta)[j](lambda)),ylim=c(-1,1)/2,main="lasso")#c(-16,16))
abline(h=0,lty=2,lwd=0.7)
abline(v=s[2]/s[3],lty=2,lwd=0.7)
legend(1,15,legend=c("comlasso","adaptive_comlasso"))
s = rowSums(abs(t(f2$beta.rec[[1]])))
matplot(c(s[1],s[3],s[2])/s[2],t(f2$beta.rec[[1]]),type="b",xaxt="n",
xlab=expression(paste(group("|", beta(lambda), "||")[1], "/" ,
group("||", beta(0), "|")[1])),
ylab=expression(hat(beta)[j](lambda)),ylim=c(-1,1)/2,main="adaptive lasso")#c(-16,16))
abline(h=0,lty=2,lwd=0.7)
abline(v=s[3]/s[2],lty=2,lwd=0.7)
par(op)
rm(list = ls())
# load data
load("./bsi_new.RData");
library(comlasso)
n <- 28
gs <- matrix(0,107,4)
gname <- colnames(x)
wt <- function(x,y){wilcox.test(x[y==1], x[y==-1])$p.value}
pval <- apply(x[,gname],2,wt,y)
tmp <- data.frame(ugenera,pval)
aa <- tmp[sort(tmp[,2],decreasing=F,index=T)$ix,][1:10,]
names(ugenera) <- ugenera
selvar <- match(as.character(aa[,1]), ugenera)
###### Figure 2-(a) ######
fit2 <- comlasso(ltype="classification",n,p=1,K=107,max.steps=100,
x,y,gam=0,weights=NULL)
par(mar=c(5.1, 4.1, 4.1, 2.1)-c(0,0,2,-1.5))
can.lam <- exp(seq(log(max(fit2$lambda)),1e-5,length=50))
can.gam <- c(-0.2,-0.1,0)
mgs2 <- vector(mode="list",length=length(can.gam))
for(j in 1:length(can.gam))
mgs2[[j]] <- matrix(0,28,length(can.lam))
for(j in 1:length(can.gam)){
for(i in 1:28){
loo <- comlasso(ltype="classification",n-1,p=1,K=107,max.steps=1e2,x[-i,],y[-i],gam=can.gam[j], weights=NULL)
est <- predict.comlasso(loo,newx=x[i,,drop=F],s=can.lam,type="fit",mode="lambda")$fit
mgs2[[j]][i,] <- est*y[i]
}
}
par(mar=c(5,4,4,3)-c(0.8,-0.2,3,1.8))
plot(can.lam,apply(mgs2[[1]],2,function(x){mean(x<0)}),
col=1,lty=1,type="s",lwd=2,
ylab="leave-one-out error rate",
xlab=expression(lambda),ylim=c(0.10,0.55),
cex=1.5,cex.axis=1.2,cex.lab=1.5)
points(can.lam, apply(mgs2[[2]],2,function(x){mean(x<0)}),col=2,lty=2,type="s",lwd=2,cex=2)
points(can.lam, apply(mgs2[[3]],2,function(x){mean(x<0)}),col=3,lty=3,type="s",lwd=2,cex=2)
legend(3,0.2,legend=c(expression(gamma==-0.2),expression(gamma==-0.1),expression(gamma==0)),col=c(1,2,3),lty=c(1,2,3),bty="n",ncol=1,cex=1.5)
###### Figure 2-(b) ######
fit3 <- comlasso(ltype="classification",n,p=length(K),K=K,
max.steps=100,x2,y,gam=0,weights=NULL)
coeffs <- predict.comlasso(fit3,newx=x2,s=fit3$lambda,type="coefficients",mode="lambda")$coefficients
b <- sum(abs(coeffs[71,]))
a <- rowSums(abs(coeffs))
can.lam <- exp(seq(log(max(fit3$lambda)),1e-5,length=50))
can.gam <- c(-0.2,-0.1,0)
mgs3 <- vector(mode="list",length=length(can.gam))
for(j in 1:length(can.gam))
mgs3[[j]] <- matrix(0,28,length(can.lam))
for(j in 1:length(can.gam)){
for(i in 1:28){
loo <- comlasso(ltype="classification",n-1,p=length(K),K=K,
max.steps=1e2,x2[-i,],y[-i],gam=can.gam[j], weights=NULL)
print(i)
est <- predict.comlasso(loo,newx=x2[i,,drop=F],s=can.lam,type="fit",mode="lambda")$fit
mgs3[[j]][i,] <- est*y[i]
}
}
par(mar=c(5,4,4,3)-c(0.8,-0.2,3,1.8))
plot(can.lam, apply(mgs3[[1]],2,function(x){mean(x<0)}),
col=1,lty=1,type="s",lwd=2,
ylab="leave-one-out error rate",
xlab=expression(lambda),ylim=c(0.10,0.55),
cex=1.5,cex.axis=1.2,cex.lab=1.5)
points(can.lam,apply(mgs3[[2]],2,function(x){mean(x<0)}),col=2,lty=2,type="s",lwd=2,cex=2)
points(can.lam,apply(mgs3[[3]],2,function(x){mean(x<0)}),col=3,lty=3,type="s",lwd=2,cex=2)
legend(3,0.2,legend=c(expression(gamma==-0.2),expression(gamma==-0.1),expression(gamma==0)),col=c(1,2,3),lty=c(1,2,3),bty="n",ncol=1,cex=1.5)
###### Figure 2-(c) ######
fit1 <- comlasso(ltype="classification", n, p=1, K=length(selvar), x[,selvar], y, gam=0, weights=NULL)
can.lam <- exp(seq(log(max(fit1$lambda)),1e-5,length=50))
can.gam <- c(-0.2,-0.1,0)
mgs1 <- vector(mode="list",length=length(can.gam))
for(j in 1:length(can.gam))
mgs1[[j]] <- matrix(0,28,length(can.lam))
for(j in 1:length(can.gam)){
for(i in 1:28){
loo <- comlasso(ltype="classification", n-1, p=1, K=length(selvar), x[-i,selvar], y[-i], gam=can.gam[j], weights=NULL)
est <- predict.comlasso(loo,newx=x[i,selvar,drop=F],s=can.lam,type="fit",mode="lambda")$fit
mgs1[[j]][i,] <- est*y[i]
}
}
par(mar=c(5,4,4,3)-c(0.8,-0.2,3,1.8))
plot(can.lam,apply(mgs1[[1]],2,function(x){mean(x<0)}),
col=1,lty=1,type="s",lwd=2,
ylab="leave-one-out error rate",
xlab=expression(lambda),ylim=c(0.10,0.55),
cex=1.5,cex.axis=1.2,cex.lab=1.5)
points(can.lam, apply(mgs1[[2]],2,function(x){mean(x<0)}),col=2,lty=2,type="s",lwd=2,cex=2)
points(can.lam, apply(mgs1[[3]],2,function(x){mean(x<0)}),col=3,lty=3,type="s",lwd=2,cex=2)
legend(3,0.2,legend=c(expression(gamma==-0.2),expression(gamma==-0.1),expression(gamma==0)),col=c(1,2,3),lty=c(1,2,3),bty="n",ncol=1,cex=1.5)
rm(list = ls())
# load data
load("./bsi_new.RData");
library(comlasso)
n <- 28
gs <- matrix(0,107,4)
gname <- colnames(x)
wt <- function(x,y){wilcox.test(x[y==1], x[y==-1])$p.value}
pval <- apply(x[,gname],2,wt,y)
tmp <- data.frame(ugenera,pval)
aa <- tmp[sort(tmp[,2],decreasing=F,index=T)$ix,][1:10,]
names(ugenera) <- ugenera
selvar <- match(as.character(aa[,1]), ugenera)
###### Figure 3 (left panel) ######
fit2 <- comlasso(ltype="classification",n,p=1,K=107,max.steps=100,
x,y,gam=0,weights=NULL)
coeffs <- predict.comlasso(fit2,newx=x2,s=fit2$lambda,type="coefficients",mode="lambda")$coefficients
b <- sum(abs(coeffs[nrow(coeffs),]))
a <- rowSums(abs(coeffs))
matplot(a/b,t(fit2$beta.rec[[1]][1:20,]),type="l",ylim=c(-0.5,0.5),ylab="coeffients",cex.axis=0.8, cex.lab=0.9,
xlab=expression(sum(hat(beta)[j](lambda),j=1,107)/sum(abs(hat(beta)[j](0)),j==1,107)), lwd=3, main=uphylum[1])
matplot(a/b,t(fit2$beta.rec[[1]][21:30,]),type="l",ylim=c(-0.5,0.5),ylab="coeffients",cex.axis=0.8, cex.lab=0.9,
xlab=expression(sum(hat(beta)[j](lambda),j=1,107)/sum(abs(hat(beta)[j](0)),j==1,107)), lwd=3, main=uphylum[2])
matplot(a/b,t(fit2$beta.rec[[1]][31:92,]),type="l",ylim=c(-0.5,0.5),ylab="coeffients",cex.axis=0.8, cex.lab=0.9,
xlab=expression(sum(hat(beta)[j](lambda),j=1,107)/sum(abs(hat(beta)[j](0)),j==1,107)), lwd=3, main=uphylum[3])
matplot(a/b,t(fit2$beta.rec[[1]][93:107,]),type="l",ylim=c(-0.5,0.5),ylab="coeffients",cex.axis=0.8, cex.lab=0.9,
xlab=expression(sum(hat(beta)[j](lambda),j=1,107)/sum(abs(hat(beta)[j](0)),j==1,107)), lwd=3, main=uphylum[4])
###### Figure 3 (right panel) ######
fit3 <- comlasso(ltype="classification",n,p=length(K),K=K,
max.steps=100,x2,y,gam=0,weights=NULL)
# solution path
coeffs <- predict.comlasso(fit3,newx=x2,s=fit3$lambda,type="coefficients",mode="lambda")$coefficients
b <- sum(abs(coeffs[71,]))
a <- rowSums(abs(coeffs))
matplot(a/b,t(fit3$beta.rec[[1]]),type="l",ylim=c(-0.5,0.5),ylab="coeffients",cex.axis=0.8, cex.lab=0.9,
xlab=expression(sum(hat(beta)[j](lambda),j=1,107)/sum(abs(hat(beta)[j](0)),j==1,107)), lwd=3, main=uphylum[1])
matplot(a/b,t(fit3$beta.rec[[2]]),type="l",ylim=c(-0.5,0.5),ylab="coeffients",cex.axis=0.8, cex.lab=0.9,
xlab=expression(sum(hat(beta)[j](lambda),j=1,107)/sum(abs(hat(beta)[j](0)),j==1,107)), lwd=3, main=uphylum[2])
matplot(a/b,t(fit3$beta.rec[[3]]),type="l",ylim=c(-0.5,0.5),ylab="coeffients",cex.axis=0.8, cex.lab=0.9,
xlab=expression(sum(hat(beta)[j](lambda),j=1,107)/sum(abs(hat(beta)[j](0)),j==1,107)), lwd=3, main=uphylum[3])
matplot(a/b,t(fit3$beta.rec[[4]]),type="l",ylim=c(-0.5,0.5),ylab="coeffients",cex.axis=0.8, cex.lab=0.9,
xlab=expression(sum(hat(beta)[j](lambda),j=1,107)/sum(abs(hat(beta)[j](0)),j==1,107)), lwd=3, main=uphylum[4])
